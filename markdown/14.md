

# 配置ip

**在我们克隆虚拟机后生成的虚拟机的IP地址是一样的，此时我们需要修改每个虚拟机的IP地址使其不一样**

```
编辑->虚拟网络编辑器->NAT模式->更改设置->NAT模式->改子网IP为：
192.1683.121.0
NAT设置：网关为192.168.121.2
DHCP设置改为192.168.121.128-192.168.121.254
确定->应用->确定
```

**主机名与ip地址映射配置(只改02和03）**

**配置主机名：**

```
vim /etc/sysconfig/network 更改hostname 
```

**hostname:查看主机名称 **

```
vim /etc/hostname 
```

**查看ip地址可选范围（每台都要改）**

```
Vim /etc/hosts
```

**输入IP与主机名的映射**

```
192.168.121.134 hadoop01

192.168.121.135 hadoop02

192.168.121.136 hadoop03
```



### 红帽补丁

#### 安装epel-release

>很多的rpm包在红帽中找不到，此时需要安装epel-release

```
yum install -y epel-release
```



### 关闭防火墙

```
systemctl stop firewalld
systemctl disable firewalld.service
```

# 三个虚拟机的配置

**修改其他的虚拟机IP地址，避免重复**

```
vim /etc/sysconfig/network-scripts/ifcfg
```

**将IPADDR修改最后的掩码**

```
hadoop02修改为 ：192.168.121.135
Hadoop03修改为 ：192.168.121.136
```

**查看主机名称**

**测试hadoop03**

```
[root@hadoop03 ~]# hostname
hadoop03
[root@hadoop03 ~]# ping huya.com
PING huya.com (106.52.191.105) 56(84) bytes of data.
64 bytes from 106.52.191.105 (106.52.191.105): icmp_seq=1 ttl=128 time=19.4 ms
64 bytes from 106.52.191.105 (106.52.191.105): icmp_seq=2 ttl=128 time=19.6 ms
^C
--- huya.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 3ms
rtt min/avg/max/mdev = 19.381/19.492/19.604/0.178 ms
```

**测试hadoop02**

```
[root@hadoop02 ~]# hostname
hadoop02
[root@hadoop02 ~]# ping huya.com
PING huya.com (106.52.191.105) 56(84) bytes of data.
64 bytes from 106.52.191.105 (106.52.191.105): icmp_seq=1 ttl=128 time=19.1 ms
64 bytes from 106.52.191.105 (106.52.191.105): icmp_seq=2 ttl=128 time=19.4 ms
^C
--- huya.com ping statistics ---
5 packets transmitted, 5 received, 0% packet loss, time 11ms
rtt min/avg/max/mdev = 18.742/19.417/20.117/0.490 ms
```

**测试hadoop01**

```
[root@hadoop01 ~]# hostname
hadoop01
[root@hadoop01 ~]# hostname
hadoop01
[root@hadoop01 ~]# ping huay.com
PING huay.com (104.18.31.204) 56(84) bytes of data.
64 bytes from 104.18.31.204 (104.18.31.204): icmp_seq=1 ttl=128 time=152 ms
^C
--- huay.com ping statistics ---
2 packets transmitted, 1 received, 50% packet loss, time 2ms
rtt min/avg/max/mdev = 152.067/152.067/152.067/0.000 ms
```

**分别关闭防火墙**

```
systemctl stop firewalld
systemctl disable firewalld.service
```

[toc]

## 集群配置

### 3.2.4 集群配置

### 1）集群部署规划

​     **注意：**

**Ø NameNode和SecondaryNameNode不要安装在同一台服务器**

**Ø ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。**

|      | hadoop102          | hadoop103                    | hadoop104                              |
| ---- | ------------------ | ---------------------------- | -------------------------------------- |
| HDFS | NameNode  DataNode | DataNode                     | SecondaryNameNode             DataNode |
| YARN | NodeManager        | ResourceManager  NodeManager | NodeManager                            |

### 2）配置文件说明

**Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。**

**（1）默认配置文件：**

| 要获取的默认文件   | 文件存放在Hadoop的jar包中的位置                           |
| ------------------ | --------------------------------------------------------- |
| core-default.xml   | hadoop-common-3.1.3.jar/core-default.xml                  |
| hdfs-default.xml   | hadoop-hdfs-3.1.3.jar/hdfs-default.xml                    |
| yarn-default.xml   | hadoop-yarn-common-3.1.3.jar/yarn-default.xml             |
| mapred-default.xml | hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml |

**（2）自定义配置文件：**

​    **core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml**四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。

### 3）配置集群

**（1）核心配置文件**

**配置core-site.xml**

```
 cd $HADOOP_HOME/etc/hadoop

 vim core-site.xml
```

文件内容如下：

```
<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- 指定NameNode的地址 -->

  <property>

​    <name>fs.defaultFS</name>

​    <value>hdfs://hadoop102:8020</value>

  </property>


  <!-- 指定hadoop数据的存储目录 -->

  <property>

​    <name>hadoop.tmp.dir</name>

​    <value>/opt/module/hadoop-3.1.3/data</value>

  </property>

 

  <!-- 配置HDFS网页登录使用的静态用户为atguigu -->

  <property>

​    <name>hadoop.http.staticuser.user</name>

​    <value>atguigu</value>

  </property>

</configuration>
```

**（2）HDFS配置文件**

配置hdfs-site.xml

```
# vim hdfs-site.xml
```

文件内容如下：

```
<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

 

<configuration>

  <!-- nn web端访问地址-->

  <property>

​    <name>dfs.namenode.http-address</name>

​    <value>hadoop102:9870</value>

  </property>

  <!-- 2nn web端访问地址-->

  <property>

​    <name>dfs.namenode.secondary.http-address</name>

​    <value>hadoop104:9868</value>

  </property>

</configuration>
```

（3）YARN配置文件

配置yarn-site.xml

```
# vim yarn-site.xml
```

文件内容如下：

```
<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

 

<configuration>

  <!-- 指定MR走shuffle -->

  <property>

​    <name>yarn.nodemanager.aux-services</name>

​    <value>mapreduce_shuffle</value>

  </property>

 

  <!-- 指定ResourceManager的地址-->

  <property>

​    <name>yarn.resourcemanager.hostname</name>

​    <value>hadoop103</value>

  </property>

 

  <!-- 环境变量的继承 -->

  <property>

​    <name>yarn.nodemanager.env-whitelist</name>

​    <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>

  </property>

</configuration>
```

**（4）MapReduce配置文件**

配置mapred-site.xml

```
 vim mapred-site.xml
```

文件内容如下：

```
<?xml version="1.0" encoding="UTF-8"?>

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- 指定MapReduce程序运行在Yarn上 -->

  <property>

​    <name>mapreduce.framework.name</name>

​    <value>yarn</value>

  </property>

</configuration>
```

**4）在集群上分发配置好的Hadoop配置文件**

```
xsync /opt/module/hadoop-3.1.3/etc/hadoop/
```

**5）去103和104上查看文件分发情况**

```
cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml

cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
```

[toc]

# 配置ssh

###  检查是否安装ssh

![image-20220327220936458](https://s2.loli.net/2022/03/27/A4H1ZFGQNrm8oVn.png)



### 查看服务是否启动

**若没有安装则使用yum install openssh-server  安装**

![image-20220327221026234](https://s2.loli.net/2022/03/27/aA6d27ri1M3jksP.png)

----


``` 
ssh-copy-id hadoop02
```

**拷贝到02，实现免密登陆**

```
[root@mail ~]# cd /root/.ssh/
[root@mail .ssh]# ll
total 16
-rw------- 1 root root  571 Mar 27 14:05 authorized_keys
-rw------- 1 root root 2655 Mar 27 14:06 id_rsa
-rw-r--r-- 1 root root  573 Mar 27 14:06 id_rsa.pub
-rw-r--r-- 1 root root  942 Mar 27 14:05 known_hosts
```

1. authorized_keys：授权的对象
2. id_rsa ：私钥
3. id_rsa.pub:公钥



###  ssh免密登陆

**第一步：在三台机器上执行一下命令生成公钥和私钥**

```
Hadoop01:   ssh-keygen   -t  rsa
查看密钥对:	 cd  .ssh/     ->ls
```


**第二步：拷贝公钥到同一台机器，及将3个公钥拷贝到hadoop01上**

```
Hadoop01:  ssh-copy-id   hadoop01     ->yes->输入01的密码
```

**第三部：复制第一胎机器的公钥到其他机器**

```
Hadoop01:  scp   /root/.ssh/authorized_keys   hadoop02:/root/.ssh   ->yes->输密码
           scp   /root/.ssh/authorized_keys   hadoop03:/root/.ssh   ->yes->输密码
```

**第四步：测试**

```
Hadoop01:   ssh  hadoop02    链接hadoop02   exit退出
```

请依次在3台机器上测试



**我们先配置hadoop01**

```
ssh-keygen   -t  rsa
```

![image-20220328171439562](https://s2.loli.net/2022/03/28/Y3dpCFiJSBLTOUG.png)



**此时我们可以在root下面找到ssh文件**

```
[root@hadoop01 .ssh]# pwd
/root/.ssh
[root@hadoop01 .ssh]# ls
id_rsa  id_rsa.pub        
```

**我们需要将公钥拷贝到ssh**

```
ssh-copy-id   hadoop02  
```

![image-20220328171823862](https://s2.loli.net/2022/03/28/EfuprIhmqM6KgAW.png)

```
ssh-copy-id   hadoop03   
```

**我们使用ssh登陆，不需要密码**

```
[root@hadoop01 .ssh]# ssh root@hadoop02
Activate the web console with: systemctl enable --now cockpit.socket

Last login: Mon Mar 28 01:58:36 2022 from 192.168.121.5
[root@hadoop02 ~]# 
```

---

> 继续分别配置免密登录，步骤重复
>
> 注意：这个是针对我们的用户的，其他用户还是需要密码

**此时我们在任何一台主机都可以操控**



[toc]

[😶‍🌫️hadoop官方编程指南](https://hadoop.apache.org)

>   官方文档学习笔记很全，推荐去官网学习

😶‍🌫️[我的学习笔记：github](https://github.com/3293172751/CS_COURSE)

---

**区块链技术（也称之为分布式账本技术）**，是一种互联网数据库技术，其特点是去中心化，公开透明，让每一个人均可参与的数据库记录

>   ❤️💕💕关于区块链技术，可以关注我，共同学习更多的区块链技术。博客[http://nsddd.top](

# hadoop运行模式

![image-20220327122341782](https://s2.loli.net/2022/03/27/BUyhRuJ3QztMirf.png)

## 完全分布式搭建（重点）

**分析步骤**

1. 安装三台虚拟机（关闭防火墙、静态ip、主机名称）
2. 安装jdk
3. 配置环境变量
4. 安装hadoop
5. 配置环境变量
6. 配置集群
7. 单点启动
8. 配置ssh
9. 群起并测试集群



> 三台服务器有一台安装了gdk和hadoop此时我们需要编写一个脚本，将服务器中的程序拷贝

### scp实现安全拷贝

**scp实现服务器与服务器之间的完全数据拷贝**

**基本语法**

```
scp -r atguigu@hadoop01:/opt/module/* atguigu@hadoop02:/opt/module
```

**即使是03主机，也可以通过scp将01文件拷贝到02文件**



### rsync远程同步工具

**rsync主要用于备份和镜像，具有速度快、避免相同内容和支持符号链接的优点**

> 相比较scp,rsync速度更快，只对差异文件做更新

**第一次同步等同于拷贝**

**基本语法**

```
rsync -av atguigu@hadoop01:/opt/module atguigu@hadoop02:/opt/module
```



##  xsync集群分发脚本

**循环复制文件到所有节点的相同路径下**

**原始命令**

```
xsync -av /opt/module atguigu@hadoop02:/opt/module
```

**需求分析：**

```
xsync 同步file 
```

> 那么我们需要去配置它的环境变量


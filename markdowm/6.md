## 6.0 MapReduce 使用

### *分类* [Hadoop 教程](https://www.runoob.com/w3cnote_genre/hadoop)

在学习了之前的 MapReduce 概念之后，我们应该已经知道什么是 Map 和 Reduce，并了解了他们的工作方式。

本章将学习如何使用 MapReduce。

## Word Count

Word Count 就是"词语统计"，这是 MapReduce 工作程序中最经典的一种。它的主要任务是对一个文本文件中的词语作归纳统计，统计出每个出现过的词语一共出现的次数。

Hadoop 中包含了许多经典的 MapReduce 示例程序，其中就包含 Word Count。

**注意：**这个案例在 HDFS 不运行的状态下依然可以运行，所以我们先在单机模式下测试

首先，启动一个之前制作的 hadoop_proto 镜像的新容器：

```
docker run -d --name=word_count hadoop_proto
```

进入容器：

```
docker exec -it word_count bash
```

进入 HOME 目录：

```
cd ~
```

现在我们准备一份文本文件 input.txt：

```
I love runoob
I like runoob
I love hadoop
I like hadoop
```

将以上内容用文本编辑器保存。

执行 MapReduce：

```
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.4.jar wordcount input.txt output
```

解释一下含义：

hadoop jar从 jar 文件执行 MapReduce 任务，之后跟着的是示例程序包的路径。

wordcount表示执行示例程序包中的 Word Count 程序，之后跟这两个参数，第一个是输入文件，第二个是输出结果的目录名（因为输出结果是多个文件）。

执行之后，应该会输出一个文件夹 output，在这个文件夹里有两个文件：_SUCCESS 和 part-r-00000。

其中 _SUCCESS 只是用于表达执行成功的空文件，part-r-00000 则是处理结果，当我们显示一下它的内容：

```
cat ~/output/part-r-00000
```

你应该可以看到如下信息：

```
I       4
hadoop  2
like    2
love    2
runoob  2
```

## 集群模式

现在我们在集群模式下运行 MapReduce。

启动在上一章配置好的集群容器：

```
docker start nn dn1 dn2
```

进入 NameNode 容器：

```
docker exec -it nn su hadoop
```

进入 HOME：

```
cd ~
```

编辑 input.txt：

```
I love runoob
I like runoob
I love hadoop
I like hadoop
```

启动 HDFS：

```
start-dfs.sh
```

创建目录：

```
hadoop fs -mkdir /wordcount
hadoop fs -mkdir /wordcount/input
```

上传 input.txt

```
hadoop fs -put input.txt /wordcount/input/
```

执行 Word Count：

```
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.4.jar wordcount /wordcount/input /wordcount/output
```

查看执行结果：

```
hadoop fs -cat /wordcount/output/part-r-00000
```

如果一切正常，将会显示以下结果：

```
I       4
hadoop  2
like    2
love    2
runoob  2
```